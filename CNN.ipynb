{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_1:0' shape=(?, 16, 16, 20) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = tf.placeholder(tf.float32,(None,32,32,3),\"input\")\n",
    "filters_weights = tf.Variable(tf.truncated_normal((8,8,3,20)),\"filters_weights\")\n",
    "filter_bias = tf.Variable(tf.zeros((20)))\n",
    "strides = (1,2,2,1)\n",
    "tf.nn.conv2d(input,filters_weights,strides,\"SAME\",name=\"conv\") + filter_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Output depth\n",
    "k_output = 64\n",
    "\n",
    "# Image Properties\n",
    "image_width = 10\n",
    "image_height = 10\n",
    "color_channels = 3\n",
    "\n",
    "# Convolution filter\n",
    "filter_size_width = 5\n",
    "filter_size_height = 5\n",
    "\n",
    "# Input/Image\n",
    "input = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=[None, image_height, image_width, color_channels])\n",
    "\n",
    "# Weight and bias\n",
    "weight = tf.Variable(tf.truncated_normal(\n",
    "    [filter_size_height, filter_size_width, color_channels, k_output]))\n",
    "bias = tf.Variable(tf.zeros(k_output))\n",
    "\n",
    "# Apply Convolution\n",
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "# Add bias\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "# Apply activation function\n",
    "conv_layer = tf.nn.relu(conv_layer)\n",
    "conv_layer = tf.nn.max_pool(conv_layer,(1,2,2,1),strides=(1,2,2,1),padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.00001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Number of samples to calculate validation and accuracy\n",
    "# Decrease this if you're running out of memory to calculate accuracy\n",
    "test_valid_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75  # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, k, k, 1],\n",
    "        strides=[1, k, k, 1],\n",
    "        padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Layer 1 - 28*28*1 to 14*14*32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Layer 2 - 14*14*32 to 7*7*64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer - 7*7*64 to 1024\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch   1 -Loss: 78844.2109 Validation Accuracy: 0.109375\n",
      "Epoch  1, Batch   2 -Loss: 73488.5547 Validation Accuracy: 0.109375\n",
      "Epoch  1, Batch   3 -Loss: 55502.5469 Validation Accuracy: 0.121094\n",
      "Epoch  1, Batch   4 -Loss: 58585.8828 Validation Accuracy: 0.144531\n",
      "Epoch  1, Batch   5 -Loss: 44424.1016 Validation Accuracy: 0.152344\n",
      "Epoch  1, Batch   6 -Loss: 38952.7266 Validation Accuracy: 0.183594\n",
      "Epoch  1, Batch   7 -Loss: 34219.4844 Validation Accuracy: 0.195312\n",
      "Epoch  1, Batch   8 -Loss: 30486.9883 Validation Accuracy: 0.199219\n",
      "Epoch  1, Batch   9 -Loss: 32964.4570 Validation Accuracy: 0.195312\n",
      "Epoch  1, Batch  10 -Loss: 24467.0859 Validation Accuracy: 0.191406\n",
      "Epoch  1, Batch  11 -Loss: 28231.2441 Validation Accuracy: 0.171875\n",
      "Epoch  1, Batch  12 -Loss: 26529.5234 Validation Accuracy: 0.199219\n",
      "Epoch  1, Batch  13 -Loss: 28381.6816 Validation Accuracy: 0.183594\n",
      "Epoch  1, Batch  14 -Loss: 22020.9785 Validation Accuracy: 0.199219\n",
      "Epoch  1, Batch  15 -Loss: 22976.5215 Validation Accuracy: 0.210938\n",
      "Epoch  1, Batch  16 -Loss: 21257.7695 Validation Accuracy: 0.226562\n",
      "Epoch  1, Batch  17 -Loss: 22291.7246 Validation Accuracy: 0.246094\n",
      "Epoch  1, Batch  18 -Loss: 20683.0781 Validation Accuracy: 0.253906\n",
      "Epoch  1, Batch  19 -Loss: 23117.7871 Validation Accuracy: 0.253906\n",
      "Epoch  1, Batch  20 -Loss: 20663.0977 Validation Accuracy: 0.257812\n",
      "Epoch  1, Batch  21 -Loss: 22948.1367 Validation Accuracy: 0.269531\n",
      "Epoch  1, Batch  22 -Loss: 19977.6914 Validation Accuracy: 0.269531\n",
      "Epoch  1, Batch  23 -Loss: 17070.0059 Validation Accuracy: 0.265625\n",
      "Epoch  1, Batch  24 -Loss: 17715.4648 Validation Accuracy: 0.273438\n",
      "Epoch  1, Batch  25 -Loss: 18637.5312 Validation Accuracy: 0.277344\n",
      "Epoch  1, Batch  26 -Loss: 18251.1719 Validation Accuracy: 0.265625\n",
      "Epoch  1, Batch  27 -Loss: 14659.5127 Validation Accuracy: 0.300781\n",
      "Epoch  1, Batch  28 -Loss: 15620.0459 Validation Accuracy: 0.289062\n",
      "Epoch  1, Batch  29 -Loss: 19191.1523 Validation Accuracy: 0.285156\n",
      "Epoch  1, Batch  30 -Loss: 13802.2451 Validation Accuracy: 0.285156\n",
      "Epoch  1, Batch  31 -Loss: 17723.0703 Validation Accuracy: 0.292969\n",
      "Epoch  1, Batch  32 -Loss: 15966.9600 Validation Accuracy: 0.300781\n",
      "Epoch  1, Batch  33 -Loss: 13487.4209 Validation Accuracy: 0.324219\n",
      "Epoch  1, Batch  34 -Loss: 12824.0391 Validation Accuracy: 0.324219\n",
      "Epoch  1, Batch  35 -Loss: 14304.2979 Validation Accuracy: 0.320312\n",
      "Epoch  1, Batch  36 -Loss: 16387.9512 Validation Accuracy: 0.300781\n",
      "Epoch  1, Batch  37 -Loss: 11069.9844 Validation Accuracy: 0.300781\n",
      "Epoch  1, Batch  38 -Loss: 12275.5078 Validation Accuracy: 0.324219\n",
      "Epoch  1, Batch  39 -Loss: 12481.1523 Validation Accuracy: 0.328125\n",
      "Epoch  1, Batch  40 -Loss: 11675.5156 Validation Accuracy: 0.332031\n",
      "Epoch  1, Batch  41 -Loss: 10939.7646 Validation Accuracy: 0.339844\n",
      "Epoch  1, Batch  42 -Loss:  9944.8145 Validation Accuracy: 0.343750\n",
      "Epoch  1, Batch  43 -Loss: 11309.1758 Validation Accuracy: 0.339844\n",
      "Epoch  1, Batch  44 -Loss: 10519.0986 Validation Accuracy: 0.335938\n",
      "Epoch  1, Batch  45 -Loss: 12219.3877 Validation Accuracy: 0.355469\n",
      "Epoch  1, Batch  46 -Loss:  8844.2344 Validation Accuracy: 0.355469\n",
      "Epoch  1, Batch  47 -Loss: 11065.1855 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  48 -Loss: 10072.5723 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  49 -Loss: 11444.9336 Validation Accuracy: 0.371094\n",
      "Epoch  1, Batch  50 -Loss: 11654.3125 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  51 -Loss: 10304.6289 Validation Accuracy: 0.394531\n",
      "Epoch  1, Batch  52 -Loss: 10427.7852 Validation Accuracy: 0.402344\n",
      "Epoch  1, Batch  53 -Loss: 11730.7871 Validation Accuracy: 0.394531\n",
      "Epoch  1, Batch  54 -Loss:  8457.2910 Validation Accuracy: 0.386719\n",
      "Epoch  1, Batch  55 -Loss:  8446.4023 Validation Accuracy: 0.398438\n",
      "Epoch  1, Batch  56 -Loss:  8199.0117 Validation Accuracy: 0.406250\n",
      "Epoch  1, Batch  57 -Loss: 11760.7637 Validation Accuracy: 0.410156\n",
      "Epoch  1, Batch  58 -Loss: 10813.3770 Validation Accuracy: 0.429688\n",
      "Epoch  1, Batch  59 -Loss:  9819.4609 Validation Accuracy: 0.417969\n",
      "Epoch  1, Batch  60 -Loss:  9405.2676 Validation Accuracy: 0.433594\n",
      "Epoch  1, Batch  61 -Loss: 10548.3564 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  62 -Loss:  8155.2969 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  63 -Loss:  9684.2021 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  64 -Loss:  8388.0488 Validation Accuracy: 0.433594\n",
      "Epoch  1, Batch  65 -Loss:  7942.8394 Validation Accuracy: 0.449219\n",
      "Epoch  1, Batch  66 -Loss:  8282.0117 Validation Accuracy: 0.457031\n",
      "Epoch  1, Batch  67 -Loss:  7518.4990 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  68 -Loss:  7260.7520 Validation Accuracy: 0.449219\n",
      "Epoch  1, Batch  69 -Loss:  8055.8442 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  70 -Loss:  8118.2524 Validation Accuracy: 0.457031\n",
      "Epoch  1, Batch  71 -Loss:  8524.6172 Validation Accuracy: 0.453125\n",
      "Epoch  1, Batch  72 -Loss:  7649.2217 Validation Accuracy: 0.449219\n",
      "Epoch  1, Batch  73 -Loss:  8668.8574 Validation Accuracy: 0.457031\n",
      "Epoch  1, Batch  74 -Loss:  7212.9702 Validation Accuracy: 0.464844\n",
      "Epoch  1, Batch  75 -Loss:  7992.9575 Validation Accuracy: 0.496094\n",
      "Epoch  1, Batch  76 -Loss: 10353.6230 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch  77 -Loss:  8622.8271 Validation Accuracy: 0.488281\n",
      "Epoch  1, Batch  78 -Loss:  6968.4580 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch  79 -Loss:  5699.9072 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  80 -Loss:  7818.5581 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  81 -Loss:  6535.5625 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  82 -Loss:  6146.2319 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  83 -Loss:  6491.3174 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  84 -Loss:  7141.1406 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  85 -Loss:  7793.4492 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  86 -Loss:  7092.6006 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  87 -Loss:  6316.2637 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch  88 -Loss:  6298.1836 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch  89 -Loss:  6817.7441 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  90 -Loss:  6804.3916 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch  91 -Loss:  5201.9785 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch  92 -Loss:  6264.5674 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch  93 -Loss:  8146.3291 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch  94 -Loss:  7013.9253 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch  95 -Loss:  5582.4434 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch  96 -Loss:  5767.8774 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch  97 -Loss:  5275.1143 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch  98 -Loss:  6034.6387 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch  99 -Loss:  7226.7397 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 100 -Loss:  6017.4941 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 101 -Loss:  5562.9297 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch 102 -Loss:  3879.4800 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 103 -Loss:  5895.0332 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 104 -Loss:  4895.7871 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 105 -Loss:  4681.1465 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 106 -Loss:  4422.3350 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 107 -Loss:  4581.9102 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 108 -Loss:  4962.1299 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 109 -Loss:  3352.9707 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 110 -Loss:  5316.9951 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 111 -Loss:  6442.7949 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 112 -Loss:  3382.3555 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 113 -Loss:  3754.0635 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 114 -Loss:  4057.7651 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 115 -Loss:  3484.1755 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 116 -Loss:  3419.7661 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 117 -Loss:  6325.0728 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 118 -Loss:  5657.3320 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 119 -Loss:  5729.9434 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 120 -Loss:  4978.4683 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 121 -Loss:  3973.0127 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 122 -Loss:  5469.5459 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 123 -Loss:  4262.5527 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 124 -Loss:  4441.8320 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 125 -Loss:  5176.9224 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 126 -Loss:  3954.2058 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 127 -Loss:  3088.8271 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 128 -Loss:  4827.4658 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 129 -Loss:  5285.5791 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 130 -Loss:  4588.6582 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 131 -Loss:  2884.8760 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 132 -Loss:  3074.2715 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 133 -Loss:  2982.3606 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 134 -Loss:  4988.9131 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 135 -Loss:  4347.5942 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 136 -Loss:  3883.4038 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 137 -Loss:  6046.7598 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 138 -Loss:  5821.3354 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 139 -Loss:  3950.9863 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 140 -Loss:  3710.5269 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 141 -Loss:  2968.2905 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 142 -Loss:  3575.2935 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 143 -Loss:  3423.2495 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 144 -Loss:  3566.9639 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 145 -Loss:  4018.1233 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 146 -Loss:  4452.5259 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 147 -Loss:  3638.3884 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 148 -Loss:  3683.9502 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 149 -Loss:  3564.0537 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 150 -Loss:  3208.2925 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 151 -Loss:  3829.0308 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 152 -Loss:  2966.4565 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 153 -Loss:  3139.4280 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 154 -Loss:  3495.7959 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 155 -Loss:  4213.6079 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 156 -Loss:  3435.3132 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 157 -Loss:  2837.0498 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 158 -Loss:  2643.3828 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 159 -Loss:  3936.6636 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 160 -Loss:  3201.3975 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 161 -Loss:  3399.6111 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 162 -Loss:  3074.5781 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 163 -Loss:  2705.2852 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 164 -Loss:  3048.9561 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 165 -Loss:  3444.9683 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 166 -Loss:  1788.3767 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 167 -Loss:  3184.5776 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 168 -Loss:  3131.6206 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 169 -Loss:  2756.8472 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 170 -Loss:  4014.1069 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 171 -Loss:  3065.3457 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 172 -Loss:  2636.2026 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 173 -Loss:  3709.0938 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 174 -Loss:  3595.9121 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 175 -Loss:  3203.0903 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 176 -Loss:  4198.3335 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 177 -Loss:  2181.0015 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 178 -Loss:  2104.2046 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 179 -Loss:  2966.2036 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 180 -Loss:  2382.2505 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 181 -Loss:  2456.9905 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 182 -Loss:  2836.0962 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 183 -Loss:  4424.7456 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 184 -Loss:  1876.0359 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 185 -Loss:  2350.9949 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 186 -Loss:  2964.9541 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 187 -Loss:  3263.2114 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 188 -Loss:  3148.6096 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 189 -Loss:  3016.6729 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 190 -Loss:  3426.6155 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 191 -Loss:  2431.9463 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 192 -Loss:  2367.2449 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 193 -Loss:  2587.6777 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 194 -Loss:  2993.3838 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 195 -Loss:  3318.3892 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 196 -Loss:  3930.3193 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 197 -Loss:  3400.9504 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 198 -Loss:  2834.3477 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 199 -Loss:  3009.3999 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 200 -Loss:  2857.8320 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 201 -Loss:  2813.7144 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 202 -Loss:  3116.6492 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 203 -Loss:  3362.9839 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 204 -Loss:  2218.7151 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 205 -Loss:  2427.0256 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 206 -Loss:  2687.1626 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 207 -Loss:  2843.6006 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 208 -Loss:  2935.6975 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 209 -Loss:  3892.1917 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 210 -Loss:  2304.8872 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 211 -Loss:  3095.0144 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 212 -Loss:  2960.2842 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 213 -Loss:  2145.4507 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 214 -Loss:  2843.7388 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 215 -Loss:  3787.3770 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 216 -Loss:  1952.5032 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 217 -Loss:  2361.5283 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 218 -Loss:  2184.3335 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 219 -Loss:  2732.6626 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 220 -Loss:  1989.3826 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 221 -Loss:  1964.3667 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 222 -Loss:  2708.8228 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 223 -Loss:  1987.3630 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 224 -Loss:  2050.0095 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 225 -Loss:  2691.4316 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 226 -Loss:  1953.8628 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 227 -Loss:  1952.0173 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 228 -Loss:  2593.2314 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 229 -Loss:  1546.7516 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 230 -Loss:  2186.0359 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 231 -Loss:  2229.9346 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 232 -Loss:  2992.2642 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 233 -Loss:  2662.4404 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 234 -Loss:  2996.9023 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 235 -Loss:  1681.5861 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 236 -Loss:  1886.5623 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 237 -Loss:  1772.2830 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 238 -Loss:  1545.3716 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 239 -Loss:  1724.8490 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 240 -Loss:  1771.6948 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 241 -Loss:  2316.8647 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 242 -Loss:  2763.1880 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 243 -Loss:  2857.4163 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 244 -Loss:  2478.7515 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 245 -Loss:  2130.0466 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 246 -Loss:  3015.4380 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 247 -Loss:  2160.3171 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 248 -Loss:  1672.1992 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 249 -Loss:  2683.0679 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 250 -Loss:  1874.9087 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 251 -Loss:  2482.1177 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 252 -Loss:  2428.5264 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 253 -Loss:  2788.0056 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 254 -Loss:  2507.4846 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 255 -Loss:  3277.1587 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 256 -Loss:  1910.5265 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 257 -Loss:  2491.8345 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 258 -Loss:  1626.8585 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 259 -Loss:  2424.4839 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 260 -Loss:  2022.9814 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 261 -Loss:  1851.1252 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 262 -Loss:  2017.1234 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 263 -Loss:  2322.3149 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 264 -Loss:  1803.7991 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 265 -Loss:  1728.2668 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 266 -Loss:  1864.6257 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 267 -Loss:  1739.3242 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 268 -Loss:  1992.5524 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 269 -Loss:  3019.5483 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 270 -Loss:  2516.6362 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 271 -Loss:  3044.3713 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 272 -Loss:  2475.5093 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 273 -Loss:  2184.1179 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 274 -Loss:  1551.0737 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 275 -Loss:  1668.1985 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 276 -Loss:  1416.4473 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 277 -Loss:  1402.8602 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 278 -Loss:  2836.7573 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 279 -Loss:  2014.1130 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 280 -Loss:  1257.1755 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 281 -Loss:  1502.1667 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 282 -Loss:  2049.0842 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 283 -Loss:  1971.7346 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 284 -Loss:  1867.5212 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 285 -Loss:  2716.0728 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 286 -Loss:  2578.3022 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 287 -Loss:  1742.5768 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 288 -Loss:  2435.5391 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 289 -Loss:  2503.5518 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 290 -Loss:  2106.0859 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 291 -Loss:  2218.0747 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 292 -Loss:  2252.9619 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 293 -Loss:  1623.5889 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 294 -Loss:  1896.5194 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 295 -Loss:  2869.9192 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 296 -Loss:  1830.3665 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 297 -Loss:  3326.0732 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 298 -Loss:  2068.5400 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 299 -Loss:  1346.8771 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 300 -Loss:  1404.3275 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 301 -Loss:  1557.8723 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 302 -Loss:  1131.0854 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 303 -Loss:  1409.1150 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 304 -Loss:  1396.7869 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 305 -Loss:  1511.6138 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 306 -Loss:  2304.8491 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 307 -Loss:  1984.1844 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 308 -Loss:  2377.0662 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 309 -Loss:  2028.9805 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 310 -Loss:  1167.0023 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 311 -Loss:  1540.2104 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 312 -Loss:  2089.8662 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 313 -Loss:  2532.5942 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 314 -Loss:  1734.2318 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 315 -Loss:  1371.6582 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 316 -Loss:  2036.2472 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 317 -Loss:  1989.0657 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 318 -Loss:  2012.9102 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 319 -Loss:  1725.3280 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 320 -Loss:  2311.4395 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 321 -Loss:  2611.9812 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 322 -Loss:  1904.4132 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 323 -Loss:  2037.3071 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 324 -Loss:  1741.9207 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 325 -Loss:  1701.2461 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 326 -Loss:  1970.1278 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 327 -Loss:  1551.7521 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 328 -Loss:  1569.0579 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 329 -Loss:  1099.3878 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 330 -Loss:  1259.3027 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 331 -Loss:  1731.0045 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 332 -Loss:  1971.2007 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 333 -Loss:  2026.0188 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 334 -Loss:  1837.3994 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 335 -Loss:  1265.8350 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 336 -Loss:  2366.6030 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 337 -Loss:  1644.6888 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 338 -Loss:   903.5639 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 339 -Loss:  2224.5864 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 340 -Loss:  1360.8466 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 341 -Loss:  1473.9658 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 342 -Loss:  1284.4611 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 343 -Loss:  1426.5775 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 344 -Loss:  2833.7114 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 345 -Loss:  1988.0713 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 346 -Loss:  2186.3420 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 347 -Loss:  1311.9629 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 348 -Loss:  2352.9517 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 349 -Loss:  2117.4468 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 350 -Loss:  1836.8784 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 351 -Loss:  2129.2229 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 352 -Loss:  1656.6345 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 353 -Loss:   996.5388 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 354 -Loss:  1204.2068 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 355 -Loss:  2502.1172 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 356 -Loss:  1198.8501 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 357 -Loss:  1976.3214 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 358 -Loss:  2024.5754 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 359 -Loss:  1517.3813 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 360 -Loss:  1342.1687 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 361 -Loss:  1167.3608 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 362 -Loss:  1259.8326 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 363 -Loss:  1633.8669 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 364 -Loss:  1359.2444 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 365 -Loss:  1281.3057 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 366 -Loss:  1247.0822 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 367 -Loss:  1718.9722 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 368 -Loss:  1560.4316 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 369 -Loss:  1864.3700 Validation Accuracy: 0.738281\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a0a709d70f6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 keep_prob: 1.})\n\u001b[0m\u001b[1;32m     37\u001b[0m             valid_acc = sess.run(accuracy, feed_dict={\n\u001b[1;32m     38\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_valid_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fabien/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fabien/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fabien/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/fabien/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fabien/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(\\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf. global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: dropout})\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "\n",
    "            print('Epoch {:>2}, Batch {:>3} -'\n",
    "                  'Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                epoch + 1,\n",
    "                batch + 1,\n",
    "                loss,\n",
    "                valid_acc))\n",
    "\n",
    "    # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_3:0' shape=(1, 2, 2, 3) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Setup the strides, padding and filter weight/bias such that\n",
    "the output shape is (1, 2, 2, 3).\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# `tf.nn.conv2d` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "\n",
    "def conv2d(input):\n",
    "    # Filter (weights and bias)\n",
    "    # The shape of the filter weight is (height, width, input_depth, output_depth)\n",
    "    # The shape of the filter bias is (output_depth,)\n",
    "    # TODO: Define the filter weights `F_W` and filter bias `F_b`.\n",
    "    # NOTE: Remember to wrap them in `tf.Variable`, they are trainable parameters after all.\n",
    "    F_W = tf.Variable(tf.random_normal([3, 3, 1, 3]))\n",
    "    F_b = tf.Variable(tf.random_normal([3]))\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 1, 1, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'VALID'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv2d\n",
    "    # `tf.nn.conv2d` does not include the bias computation so we have to add it ourselves after.\n",
    "    return tf.nn.conv2d(input, F_W, strides, padding) + F_b\n",
    "\n",
    "out = conv2d(X)\n",
    "out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_6:0' shape=(1, 2, 2, 1) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Set the values to `strides` and `ksize` such that\n",
    "the output shape after pooling is (1, 2, 2, 1).\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# `tf.nn.max_pool` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "def maxpool(input):\n",
    "    # TODO: Set the ksize (filter size) for each dimension (batch_size, height, width, depth)\n",
    "    ksize = [1, 2, 2, 1]\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'VALID'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#max_pool\n",
    "    return tf.nn.max_pool(input, ksize, strides, padding)\n",
    "    \n",
    "out = maxpool(X)\n",
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
